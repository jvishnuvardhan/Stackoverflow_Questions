{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Flowers_tf_lite_Keras_Hub_Layer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvishnuvardhan/Stackoverflow_Questions/blob/master/Flowers_tf_lite_Keras_Hub_Layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6ecAvsmQp1I"
      },
      "source": [
        "## To run this colab, press the \"Runtime\" button in the menu tab and then press the \"Run all\" button."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "77gENRVX40S7"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "d8jyt37T42Vf",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hRTa3Ee15WsJ"
      },
      "source": [
        "# Recognize Flowers using Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dQHMcypT3vDT"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBMcobPHdD8O",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NOG3l_MsBO1A",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeyVJTDQS1pz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAjmKxNATAlo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import time\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v77rlkCKW0IJ"
      },
      "source": [
        "## Setup Input Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j4QOy2uA3P_p"
      },
      "source": [
        "Download the flowers dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xxL2mjVVGIrV",
        "colab": {}
      },
      "source": [
        "_URL = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "zip_file = tf.keras.utils.get_file(origin=_URL, \n",
        "                                   fname=\"flower_photos.tgz\", \n",
        "                                   extract=True)\n",
        "\n",
        "base_dir = os.path.join(os.path.dirname(zip_file), 'flower_photos')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rHPE12UTRV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use ImageDataGenerator to rescale the images.\n",
        "DATA_ROOT = base_dir#\"training_images\"\n",
        "BATCH_SIZE = 64\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,validation_split=0.25)\n",
        "# Create the train generator and specify where the train dataset directory, image size, batch size.\n",
        "train_generator = image_generator.flow_from_directory(DATA_ROOT, target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE,subset='training')\n",
        "#Create the validation generator with similar approach as the train generator with the flow_from_directory() method.\n",
        "val_generator = image_generator.flow_from_directory(DATA_ROOT, target_size=IMAGE_SHAPE, batch_size=BATCH_SIZE, subset='validation')\n",
        "                                                \n",
        "\n",
        "for image_batch, label_batch in train_generator:\n",
        "  print(\"Image batch shape: \", image_batch.shape)\n",
        "  print(\"Label batch shape: \", label_batch.shape)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZrFFcwUb3iK9"
      },
      "source": [
        "Save the labels in a file which will be downloaded later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-QFZIhWs4dsq",
        "colab": {}
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "duxD_UDSOmng",
        "colab": {}
      },
      "source": [
        "!cat labels.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHTfii2RWcZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_extractor_url = \"https://tfhub.dev/google/imagenet/mobilenet_v2_075_224/feature_vector/4\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8S0-D482WJtt",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "\"\"\"Create the feature extractor.\"\"\"\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(224,224,3))\n",
        "\n",
        "\"\"\"It returns a 1280-length vector for each image:\"\"\"\n",
        "\n",
        "feature_batch = feature_extractor_layer(image_batch)\n",
        "print(feature_batch.shape)\n",
        "\n",
        "\"\"\"Freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer.\"\"\"\n",
        "\n",
        "feature_extractor_layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bT2mI94XDAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"### Attach a classification head\n",
        "Now wrap the hub layer in a `tf.keras.Sequential` model, and add a new classification layer.\n",
        "\"\"\"\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  feature_extractor_layer,\n",
        "  tf.keras.layers.InputLayer(input_shape=IMAGE_SHAPE + (3,)),\n",
        "\n",
        "  layers.Dense(image_data.num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.build((None,)+IMAGE_SHAPE+(3,))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "predictions = model(image_batch)\n",
        "\n",
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spk2I6BOXpRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"### Train the model\n",
        "Use compile to configure the training process:\n",
        "\"\"\"\n",
        "\n",
        "model.compile(\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "\"\"\"Now use the `.fit` method to train the model.\n",
        "To keep this example short train just 2 epochs. To visualize the training progress, use a custom callback to log the loss and accuracy of each batch individually, instead of the epoch average.\n",
        "\"\"\"\n",
        "\n",
        "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.batch_losses = []\n",
        "    self.batch_acc = []\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    self.batch_losses.append(logs['loss'])\n",
        "    self.batch_acc.append(logs['accuracy'])\n",
        "    self.model.reset_metrics()\n",
        "\n",
        "\n",
        "\n",
        "#batch_size = image_data.batch_size\n",
        "#val_batch_size = validation_image.batch_size\n",
        "#batch_size = 100\n",
        "#val_batch_size = 100\n",
        "\n",
        "\n",
        "#steps_per_epoch = np.ceil(image_data.samples/batch_size)\n",
        "\n",
        "batch_stats_callback = CollectBatchStats()\n",
        "\n",
        "\"\"\"\n",
        "#measure time\n",
        "\"\"\"\n",
        "starttime = time.time()\n",
        "\n",
        "history = model.fit_generator(train_generator, epochs=10,\n",
        "                              steps_per_epoch=len(train_generator),\n",
        "                              validation_data =validation_image,\n",
        "                              validation_steps = len(val_generator), #validation_image.samples //val_batch_size,\n",
        "                              callbacks = [batch_stats_callback],shuffle=True)\n",
        "\n",
        "\"\"\"Now after, even just a few training iterations, we can already see that the model is making progress on the task.\"\"\"\n",
        "\n",
        "endtime = time.time()\n",
        "\n",
        "print(\"[[[Time Elapsed: {0} minutes\".format((endtime-starttime) // 60))\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(batch_stats_callback.batch_losses)\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(batch_stats_callback.batch_acc)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylim([0,1])\n",
        "plt.legend(['train','valid'],loc='upper left')\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylim([0,1])\n",
        "plt.legend(['train','valid'],loc='upper left')\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNpG5VDba8dI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"### Check the predictions\n",
        "To redo the plot from before, first get the ordered list of class names:\n",
        "\"\"\"\n",
        "\n",
        "classes = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\n",
        "class_names = np.array([key.title() for key, value in classes])\n",
        "class_names\n",
        "\n",
        "\"\"\"Run the image batch through the model and convert the indices to class names.\"\"\"\n",
        "\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = class_names[predicted_id]\n",
        "\n",
        "\"\"\"Plot the result\"\"\"\n",
        "\n",
        "label_id = np.argmax(label_batch, axis=-1)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
        "  plt.title(predicted_label_batch[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ANuW4pXbWr4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"## Export your model\n",
        "Now that you've trained the model, export it as a saved model:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "t = time.time()\n",
        "    \n",
        "export_path = \"latest-{}\".format(int(t))\n",
        "model.save(export_path)\n",
        "#model.save(\"kuih-{}.h5\".format(int(t)))\n",
        "\n",
        "\n",
        "print(\"Saved Model to :{}\".format(export_path))\n",
        "\n",
        "print(\"#####################\")\n",
        "print(\"Converting to TFLite ....\")\n",
        "print(\"########################\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\",\"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzLCR1lBbgzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concrete func\n",
        "cmodel=tf.keras.models.load_model(export_path)\n",
        "run_model = tf.function(lambda x : cmodel(x))\n",
        "\n",
        "concrete_func = run_model.get_concrete_function(\n",
        "    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",
        ")\n",
        "\n",
        "\n",
        "'''\n",
        "concrete_func = cmodel.signatures[\n",
        "  tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]\n",
        "concrete_func.inputs[0].set_shape([1, 224, 224, 3])\n",
        "'''\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "tflite_model = converter.convert()\n",
        "open(\"concrete_model.tflite\",\"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jof1bGYNbnGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Now confirm that we can reload it, and it still gives the same results:\"\"\"\n",
        "\n",
        "reloaded = tf.keras.models.load_model(export_path)\n",
        "\n",
        "result_batch = model.predict(image_batch)\n",
        "reloaded_result_batch = reloaded.predict(image_batch)\n",
        "\n",
        "print(abs(reloaded_result_batch - result_batch).max())\n",
        "\n",
        "\"\"\"This saved model can be loaded for inference later, or converted to [TFLite](https://www.tensorflow.org/lite/convert/) or [TFjs](https://github.com/tensorflow/tfjs-converter).\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "53OTCh3jnbwV",
        "colab": {}
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GE4w-9S410Dk"
      },
      "source": [
        "Download the converted model and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x47uW_lI1DoV",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('converted_model.tflite')\n",
        "files.download('labels.txt')\n",
        "files.download('concrete_model.tflite')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}